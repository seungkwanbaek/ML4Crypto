{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Description of the Classification Problem\n",
    "\n",
    "With the latest craze in cryptocurrency trading, there is a lot of speculation in the news about the trends in cryptocurrency prices. While similar to investment instruments (e.g. stocks, bonds), cryptocurrency are not strictly regulated by the SEC, and therefore, do not offer much financial information needed for fundamental analysis, calculating the cryptocurrency's intrinsic value. \n",
    "\n",
    "Therefore, to make sense of the price changes for cryptocurrency and uncover a pattern in this volatile market, this project aims to use supervised learning algorithms to figure out when to buy, sell, or hold Bitcoin, the most famous cryptocurrency.\n",
    "\n",
    "From Kraken Exchange, Bitcoin's daily historical price and volume data from 2014 to Jan 2018 were pulled. This was used to derive key technical indicators to predict future price levels. \n",
    "\n",
    "* Bollinger Bands percentage: a volatility indicator which creates a band of 3 lines which are plotted in relation to a security's price\n",
    "\n",
    "The output variable is the action: Strong Sell, Weak Sell, Hold, Weak Buy, and Strong Buy. These signals are based on the degree of the daily return. In this work, if the daily return exceeds 4% (decrease or increase), the signal is Strong. If the daily return is less than 4%, the signal is Weak. \n",
    "\n",
    "In summary, this project aims to classify different degrees of action on buying/selling Bitcoin based on its daily technical indicators. Because this is a time-series data, the data is not randomly split. Earlier data is used for training to test on the latter 33% of the data. \n",
    "\n",
    "In this work, cross-validation was not used because it violates the natural order of a time-series dataset.\n",
    "\n",
    "\n",
    "## 2. Metrics\n",
    "\n",
    "### a. Training and Testing Error\n",
    "\n",
    "a. Decision Tree\n",
    "b. \n",
    "\n",
    "Training time. ROC curve\n",
    "\n",
    "### b. Training Size vs. Performance\n",
    "\n",
    "### c. Training time\n",
    "learning curve\n",
    "\n",
    "## 3. Analysis\n",
    "\n",
    "\n",
    "Why did you get the results you did? Compare and contrast the different algorithms. \n",
    "\n",
    "What sort of changes might you make to each of those algorithms to improve performance? How fast were they in terms of wall clock time? Iterations? Would cross validation help (and if it would, why didn't you implement it?)? How much performance was due to the problems you chose? How about the values you chose for learning rates, stopping criteria, pruning methods, and so forth (and why doesn't your analysis show results for the different values you chose?)? Which algorithm performed best? How do you define best? Be creative and think of as many questions you can, and as many answers as you can.\n",
    "\n",
    "-Why did you get the results you did? \n",
    "\n",
    "-Compare and contrast the different algorithms. \n",
    "\n",
    "-What sort of changes might you make to each of those algorithms to improve performance? \n",
    "\n",
    "-How fast were they in terms of wall clock time? Iterations? \n",
    "\n",
    "-Would cross validation help (and if it would, why didn't you implement it?)? How much performance was due to the \n",
    "problems you chose? \n",
    "\n",
    "-How about the values you chose for learning rates, stopping criteria, pruning methods, and so forth (and why doesn't your analysis show results for the different values you chose?)? \n",
    "\n",
    "-Which algorithm performed best? \n",
    "\n",
    "* How do you define best? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In descending order from the Upper Band:\n",
    "\n",
    "%B Above 1 = Price is Above the Upper Band\n",
    "\n",
    "%B Equal to 1 = Price is at the Upper Band\n",
    "\n",
    "%B Above .50 = Price is Above the Middle Line\n",
    "\n",
    "%B Below .50 = Price is Below the Middle Line\n",
    "\n",
    "%B Equal to 0 = Price is at the Lower Band\n",
    "\n",
    "%B Below 0 = Price is Below the Lower Band\n",
    "\n",
    "Generally speaking .80 and .20 are also relevant levels.\n",
    "\n",
    "%B Above .80 = Price is Nearing the Upper Band\n",
    "%B Below .20 = Price is Nearing the Lower Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('BTCUSDKraken.csv', index_col=0, usecols=['Date','Volume (BTC)', 'Weighted Price'])\n",
    "df = df.drop('2018-01-12')\n",
    "df = df.replace([0], np.nan)\n",
    "df = df.ffill(axis=None, inplace=False, limit=None, downcast=None)\n",
    "lookback = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanbaek/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=3,center=False).mean()\n",
      "  \n",
      "/Users/bryanbaek/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=3,center=False).mean()\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "delta = df['Weighted Price'].diff()\n",
    "dUp, dDown = delta.copy(), delta.copy()\n",
    "dUp[dUp < 0] = 0\n",
    "dDown[dDown > 0] = 0\n",
    "\n",
    "RolUp = pd.rolling_mean(dUp, lookback)\n",
    "RolDown = pd.rolling_mean(dDown, lookback).abs()\n",
    "\n",
    "df['RSI'] = RolUp / RolDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanbaek/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(min_periods=3,window=3,center=False).mean()\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/bryanbaek/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: pd.ewm_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.ewm(ignore_na=False,span=3,min_periods=3,adjust=True).mean()\n",
      "  \n",
      "/Users/bryanbaek/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: FutureWarning: pd.rolling_std is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(min_periods=3,window=3,center=False).std()\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "sma = pd.rolling_mean(df['Weighted Price'], window = lookback, min_periods = lookback)\n",
    "ema = pd.ewma(df['Weighted Price'], span = lookback, min_periods = lookback)\n",
    "rolling_std = pd.rolling_std(df['Weighted Price'], window = lookback, min_periods = lookback)\n",
    "up = (rolling_std * 2) + ema\n",
    "down = (rolling_std * -2) + ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['Price/SMA'] = df['Weighted Price']/sma\n",
    "df['bbp'] = (df['Weighted Price'] - down) / (up - down)\n",
    "df['Price/EMA'] = df['Weighted Price'] / ema\n",
    "df['price_momentum'] = df['Weighted Price'].pct_change(periods = lookback - 1)\n",
    "df['vol_momentum'] = df['Volume (BTC)'].pct_change(periods = lookback - 1)\n",
    "df['bestaction'] = df['Weighted Price'].pct_change(periods = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# suggestion_conditions = [\n",
    "#     (df['Price/EMA'] < 0.97) & (df['bbp'] < 0.25),\n",
    "#     (df['Price/EMA'] > 1.01) & (df['bbp'] > 0.75)]\n",
    "\n",
    "actual_conditions = [\n",
    "    (df['bestaction'] >= 0.04), \n",
    "    ( (0.04 > df['bestaction']) & (df['bestaction'] > 0) ),\n",
    "    ( (0 > df['bestaction']) & (df['bestaction'] > -0.04) ),\n",
    "    (df['bestaction'] <= -0.04) ]\n",
    "\n",
    "choices = [2, 1, -1, -2]\n",
    "#df['Suggestion'] = np.select(suggestion_conditions, choices, default=0)\n",
    "df['Action'] = np.select(actual_conditions, choices, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Volume (BTC)', 'Weighted Price', 'bestaction'], axis=1)\n",
    "df = df.drop(df.index[0:lookback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(df.columns[0:-1])\n",
    "X = df[features]\n",
    "Y = df['Action']\n",
    "\n",
    "#Shuffle = False b/c gotta train on earlier data and test on later data \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Model Complexity Experiments\n",
    "\n",
    "Change the model by varying the hyperparameters of the model. \n",
    "\n",
    "You record RMSE errors in each case. (The k in kNN is a hyperparameter, the number of hidden nodes/layers, momentum and learning rates in a Neural Network are hyperparameters.)\n",
    "\n",
    "We would like to figure out a way to pick hyperparameters and data sizes to get the \"best\" model we can, such that it performs optimally on the test data.  By best, we mean it is the model that best generalizes: it is the model with the least bias and least variance. We can't tune our model to test data directly, as this would bias our training to our test set (and defeat the purpose of creating a general model).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 2, 'max_depth': 5, 'min_samples_leaf': 1}\n",
      "Training Error: 0.836\n",
      "Testing Error: 0.723\n",
      "Time: 1.13\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tuned_parameters = [{'max_depth': [None, 5, 10, 20], 'min_samples_split': [2, 5, 10, 20],\n",
    "                     'min_samples_leaf': [1, 2, 5, 10]}]\n",
    "\n",
    "DT = GridSearchCV(tree.DecisionTreeClassifier(), tuned_parameters)\n",
    "DT.fit(X_train, Y_train)\n",
    "\n",
    "print(DT.best_params_)\n",
    "\n",
    "# scores = cross_val_score(DT, X_train, Y_train, cv = 8)\n",
    "\n",
    "# print scores\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "Ypreds = DT.predict(X_test)\n",
    "Ypreds_training = DT.predict(X_train)\n",
    "\n",
    "DT_Training_Error = accuracy_score(Y_train, Ypreds_training)\n",
    "DT_Testing_Error = accuracy_score(Y_test, Ypreds)\n",
    "\n",
    "print (\"Training Error: %0.3f\" % DT_Training_Error)\n",
    "print (\"Testing Error: %0.3f\" % DT_Testing_Error)\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "DT_time = end-start\n",
    "print (\"Time: %0.2f\" % DT_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work used GridSearchCV to prune the Decision Tree. GridSearchCV runs through a list of parameters exhaustively and finds the best set of parameters in respect to accuracy via 8-fold Cross-Validation. \n",
    "\n",
    "This classifier uses the default Gini Impurity for the criterion. Gini Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Gini Impurity and Entropy typically yield very similar results, thus selection of this parameter is not prioritized. The minor difference is that Entorpy requires calculating log; using Gini as the criterion, therefore, can be a bit faster computationally. \n",
    "\n",
    "* min_samples_split feature refers to the minimum number of samples required to split an internal node. Smaller the min_samples_split, greater the tendency to overfit. \n",
    "* max_depth refers to the maximum depth of the tree. By default, nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. Greater the max_depth, greater the tendency to overfit. \n",
    "* min_samples_leaf refers to the minimum number of samples required to be at a leaf node. Smaller the min_samples_leaf, greater the tendency to overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Neural Networks (Multi-layer Perceptron (MLP) )\n",
    "\n",
    "\n",
    "## Features:\n",
    "\n",
    "NN = MLPClassifier(hidden_layer_sizes=(20, 5), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', \n",
    " learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    " random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    " early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    " \n",
    "* hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "\n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "hidden_layer_sizes=(10, 2) : 10 hidden layers with 2 hidden units\n",
    "\n",
    "* activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default ‘relu’\n",
    "Activation function for the hidden layer.\n",
    "\n",
    "* solver : {‘lbfgs’, ‘sgd’, ‘adam’}, default ‘adam’\n",
    "The solver for weight optimization.\n",
    "\n",
    "* learning_rate_init : double, optional, default 0.001\n",
    "The initial learning rate used. It controls the step-size in updating the weights. Only used when solver=’sgd’ or ‘adam’.\n",
    "\n",
    "* learning_rate : {‘constant’, ‘invscaling’, ‘adaptive’}, default ‘constant’\n",
    "Learning rate schedule for weight updates.\n",
    "\n",
    "* momentum : float, default 0.9\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=’sgd’.\n",
    "\n",
    "Neural Network is skewed by noise in the data. Neural networks, in general, require a very large amount of data to converge. Decision trees are great at filtering out noisy and low-information features, while a neural network might get caught up in their noise.\n",
    "\n",
    "RMSD is the square root of the average of squared errors. Sensitive to outliers. Used for regression datasets. So the accuracy score is used instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanbaek/anaconda2/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (2, 5)}\n",
      "Training Error: 0.461\n",
      "Testing Error: 0.377\n",
      "Time: 4.16\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tuned_parameters = [{'hidden_layer_sizes':[(1, 5), (1, 10), (2,5), (2,10), (10, 5), (4, 20)]}]\n",
    "\n",
    "NN = GridSearchCV(MLPClassifier(), tuned_parameters)\n",
    "NN.fit(X_train, Y_train)\n",
    "\n",
    "print(NN.best_params_)\n",
    "\n",
    "#scores = cross_val_score(NN, X_train, Y_train, cv = 10)\n",
    "#print scores\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "Ypreds = NN.predict(X_test)\n",
    "Ypreds_training = NN.predict(X_train)\n",
    "\n",
    "NN_Training_Error = accuracy_score(Y_train, Ypreds_training)\n",
    "NN_Testing_Error = accuracy_score(Y_test, Ypreds)\n",
    "\n",
    "print (\"Training Error: %0.3f\" % NN_Training_Error)\n",
    "print (\"Testing Error: %0.3f\" % NN_Testing_Error)\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "NN_time = end-start\n",
    "print (\"Time: %0.2f\" % NN_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Boosting (AdaBoost on Decision Trees)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features:\n",
    "\n",
    "1. n_estimators : integer, optional (default=10)\n",
    "The number of trees in the forest.\n",
    "\n",
    "2. learning_rate : float, optional (default=1.)\n",
    "Learning rate shrinks the contribution of each classifier by learning_rate. There is a trade-off between learning_rate and n_estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 10, 'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=15,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'learning_rate': 0.8}\n",
      "Training Error: 0.997\n",
      "Testing Error: 0.718\n",
      "Time: 0.99\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tuned_parameters = [{\n",
    "    'base_estimator':[tree.DecisionTreeClassifier(max_depth=10, min_samples_split=15, min_samples_leaf=5)], \n",
    "    'n_estimators':[5, 10], \n",
    "    'learning_rate':[1, 0.8, 0.5]\n",
    "}]\n",
    "\n",
    "Boost = GridSearchCV(AdaBoostClassifier(), tuned_parameters)\n",
    "Boost.fit(X_train, Y_train)\n",
    "\n",
    "print(Boost.best_params_)\n",
    "\n",
    "#scores = cross_val_score(NN, X_train, Y_train, cv = 10)\n",
    "#print scores\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "Ypreds = Boost.predict(X_test)\n",
    "Ypreds_training = Boost.predict(X_train)\n",
    "\n",
    "Boost_Training_Error = accuracy_score(Y_train, Ypreds_training)\n",
    "Boost_Testing_Error = accuracy_score(Y_test, Ypreds)\n",
    "\n",
    "print (\"Training Error: %0.3f\" % Boost_Training_Error)\n",
    "print (\"Testing Error: %0.3f\" % Boost_Testing_Error)\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "Boost_time = end - start\n",
    "print (\"Time: %0.2f\" % Boost_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-at least 2 kernel functions\n",
    "\n",
    "Pros: \n",
    "* Effective in high dimensional spaces.\n",
    "* Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "* Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "* Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "Cons:\n",
    "\n",
    "* If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "* SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation\n",
    "\n",
    "## Features:\n",
    "\n",
    "1. Kernel(Linear, RBF, poly, sigmoid, precomputed)\n",
    "\n",
    "Linear kernel = Straight Line (hyperplane) as the decision boundary\n",
    "* rarely used in practice\n",
    "\n",
    "Radial Basis Function (RBF) = commonly used kernel in SVC\n",
    "2 parameters:\n",
    "* gamma\n",
    "* C\n",
    "\n",
    "2. Gamma:\n",
    "*  'spread' of the kernel and therefore the decision region.\n",
    "* low gamma -> the 'curve' of the decision boundary is very low and thus the decision region is very broad (underfitting)\n",
    "* gamma = 10 (The decision boundary starts to be highly effected by individual data points (i.e. variance)).\n",
    "* high gamma -> the 'curve' of the decision boundary is high, which creates islands of decision-boundaries around data points (overfitting)\n",
    "* If gamma is ‘auto’ then 1/n_features will be used instead.\n",
    "* gamma defines how much influence a single training example has. \n",
    "* The larger gamma is, the closer other examples must be to be affected.\n",
    "\n",
    "3. C:\n",
    "* trades off misclassification of training examples against simplicity of the decision surface\n",
    "* A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly\n",
    "* penalty for misclassifying a data point\n",
    "* small C -> classifier is okay with misclassified data points (high bias, low variance)\n",
    "* big C -> classifier is heavily penalized for misclassified data and therefore bends over backwards avoid any misclassified data points (low bias, high variance)\n",
    "\n",
    "C > 10 is too slow\n",
    "\n",
    "4. degree : int, optional (default=3)\n",
    "* Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "\n",
    "SVM = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "          decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "          max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "          tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "Training Error: 0.721\n",
      "Testing Error: 0.610\n",
      "Time: 1.32\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tuned_parameters = [{\n",
    "    'kernel':('rbf', 'sigmoid'), \n",
    "    'gamma': [0.001, 0.0001],\n",
    "    'C':[1, 10, 100, 1000]\n",
    "}]\n",
    "\n",
    "SVM = GridSearchCV(SVC(), tuned_parameters)\n",
    "SVM.fit(X_train, Y_train)\n",
    "\n",
    "print(SVM.best_params_)\n",
    "\n",
    "Ypreds = SVM.predict(X_test)\n",
    "Ypreds_training = SVM.predict(X_train)\n",
    "\n",
    "SVM_Training_Error = accuracy_score(Y_train, Ypreds_training)\n",
    "SVM_Testing_Error = accuracy_score(Y_test, Ypreds)\n",
    "\n",
    "print (\"Training Error: %0.3f\" % SVM_Training_Error)\n",
    "print (\"Testing Error: %0.3f\" % SVM_Testing_Error)\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "SVM_time = end - start\n",
    "print (\"Time: %0.2f\" % SVM_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 20}\n",
      "Training Error: 1.000\n",
      "Testing Error: 0.549\n",
      "Time: 0.46\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tuned_parameters = [{\n",
    "    'weights':('uniform', 'distance'), \n",
    "    'n_neighbors': [2, 3, 5, 10, 20],\n",
    "    'leaf_size': [20, 30]\n",
    "}]\n",
    "\n",
    "KNN = GridSearchCV(KNeighborsClassifier(), tuned_parameters)\n",
    "KNN.fit(X_train, Y_train)\n",
    "\n",
    "print(KNN.best_params_)\n",
    "\n",
    "Ypreds = KNN.predict(X_test)\n",
    "Ypreds_training = KNN.predict(X_train)\n",
    "\n",
    "KNN_Training_Error = accuracy_score(Y_train, Ypreds_training)\n",
    "KNN_Testing_Error = accuracy_score(Y_test, Ypreds)\n",
    "\n",
    "print (\"Training Error: %0.3f\" % KNN_Training_Error)\n",
    "print (\"Testing Error: %0.3f\" % KNN_Testing_Error)\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "KNN_time = end - start\n",
    "print (\"Time: %0.2f\" % KNN_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features:\n",
    "\n",
    "1. weights : str or callable, optional (default = ‘uniform’)\n",
    "weight function used in prediction. Possible values:\n",
    "\n",
    "* uniform : uniform weights. All points in each neighborhood are weighted equally.\n",
    "\n",
    "* distance : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', \n",
    "                           leaf_size=30, p=2, metric='minkowski', metric_params=None, \n",
    "                           n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-d66eced9126c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-d66eced9126c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ROC curve\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"Decision Tree\", \"Neural Network\", \"AdaBoost\", \"SVM\", \"KNN\"]\n",
    "\n",
    "#implement ROC Curves\n",
    "\n",
    "h = .02 \n",
    "\n",
    "classifiers = [DT, NN, Boost, SVM, KNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(Y_test, Ypreds)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "class_names = [-2, -1, 1, 2]\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "n_classes = 4\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    "y_score = classifier.fit(X_train, Y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(Y_test, Ypreds, pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.learning_curve import learning_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Learning Curves (KNN)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "\n",
    "plot_learning_curve(DT, title, X, Y, ylim=(0.4, 1.01), n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "plot_learning_curve(SVM, title, X, Y, (0.4, 1.01), n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "plot_learning_curve(SVM, title, X, Y, (0.4, 1.01), n_jobs=4)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
